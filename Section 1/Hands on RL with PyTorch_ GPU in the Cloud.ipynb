{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Hands on RL with PyTorch: GPU in the Cloud.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"0y2ZlNhxEkRl","colab_type":"text"},"source":["**PyTorch with GPU in the Cloud**\n","\n","To enable GPU usage go to Edit -> Notebook settings -> Hardware accelerator and select GPU\n"]},{"cell_type":"code","metadata":{"id":"4eRu7RMjEctD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"1391f0a3-dc37-45be-c413-86ecd792fe35","executionInfo":{"status":"ok","timestamp":1557280626920,"user_tz":240,"elapsed":1454,"user":{"displayName":"Jim DiLorenzo","photoUrl":"","userId":"09166577195279766198"}}},"source":["import torch\n","\n","if torch.cuda.is_available(): \n","    device = torch.device('cuda') \n","    print(\"GPU device is available\")\n","else:                                                   \n","    device = torch.device('cpu') \n","    print(\"GPU device is NOT available\")\n"],"execution_count":18,"outputs":[{"output_type":"stream","text":["GPU device is available\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UaAzMbK-FaiA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":120},"outputId":"5707df26-7784-49c8-9d0c-da7dbedb49f0","executionInfo":{"status":"ok","timestamp":1557280634881,"user_tz":240,"elapsed":1498,"user":{"displayName":"Jim DiLorenzo","photoUrl":"","userId":"09166577195279766198"}}},"source":["# create PyTorch tensor\n","x = torch.rand(5, 5)\n","\n","# attach tensor to GPU device\n","x = x.to(device)\n","print(\"Is tensor x on the GPU: {} \".format(x.is_cuda))\n","print(x)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Is tensor x on the GPU: True \n","tensor([[0.2592, 0.1406, 0.1285, 0.6479, 0.9417],\n","        [0.4162, 0.4540, 0.3938, 0.8868, 0.1468],\n","        [0.2771, 0.8345, 0.6770, 0.4588, 0.1046],\n","        [0.3656, 0.3302, 0.2558, 0.6792, 0.1447],\n","        [0.3718, 0.2246, 0.9507, 0.4451, 0.6309]], device='cuda:0')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eudSJ-hHF0SB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":103},"outputId":"04e52d18-91c2-4b71-8487-b53f748ad299","executionInfo":{"status":"ok","timestamp":1557280636874,"user_tz":240,"elapsed":806,"user":{"displayName":"Jim DiLorenzo","photoUrl":"","userId":"09166577195279766198"}}},"source":["# can also attach PyTorch Neural Network modules from torch.nn to GPU\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class NeuralNetwork(nn.Module):\n","    def __init__(self):\n","      super(NeuralNetwork, self).__init__()\n","      self.dense_layer_1 = nn.Linear(4, 32)\n","      self.dense_layer_2 = nn.Linear(32, 2)\n","\n","    def forward(self, x):\n","      x = F.relu(self.dense_layer_1(x))\n","      return F.relu(self.dense_layer_2(x))\n","    \n","neural_net = NeuralNetwork().to(device)\n","\n","print(\"Is neural network on the GPU: {} \".format(next(neural_net.parameters()).is_cuda))\n","print(neural_net)\n"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Is neural network on the GPU: True \n","NeuralNetwork(\n","  (dense_layer_1): Linear(in_features=4, out_features=32, bias=True)\n","  (dense_layer_2): Linear(in_features=32, out_features=2, bias=True)\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7JY8BvKUKLwu","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}